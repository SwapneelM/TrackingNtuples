{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of events in data\n",
    "number_of_events_ = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the DataFrames Stored during Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Refer to Data Preprocessing Notebook to Understand the Semantics and Column Headers'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Refer to Data Preprocessing Notebook to Understand the Semantics and Column Headers'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_global_df_ = pd.read_msgpack('data/track_global_df_.msgpack')\n",
    "track_param_global_df_ = pd.read_msgpack('data/track_param_global_df_.msgpack')\n",
    "rechit_global_df_ = pd.read_msgpack('data/rechit_global_df_.msgpack')\n",
    "rechit_param_global_df_ = pd.read_msgpack('data/rechit_param_global_df_.msgpack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_count_ = pd.DataFrame.to_dict(pd.read_csv('data/track_count_.csv'))\n",
    "rechit_count_ = pd.DataFrame.to_dict(pd.read_csv('data/rechit_count_.csv'))\n",
    "track_ids_ = pd.DataFrame.to_dict(pd.read_csv('data/track_ids_.csv'))\n",
    "rechit_ids_ = pd.DataFrame.to_dict(pd.read_csv('data/rechit_ids_.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Adjacency Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nGraphs are created on a per-event basis. We build an adjacency matrix of rechits for each individual event.\\nThe rechit connections are defined by the track that they belong to.\\nThe target label for each node is taken as the first tp_index in its rechit_tp_list\\n\\n#ToDo: Incorporate a more flexible labeling schema - can you label the edges using the 'extra' tp index?\\nCan this learn more interesting structures for the graph(s)?\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Graphs are created on a per-event basis. We build an adjacency matrix of rechits for each individual event.\n",
    "The rechit connections are defined by the track that they belong to.\n",
    "The target label for each node is taken as the first tp_index in its rechit_tp_list\n",
    "\n",
    "#TODO: Incorporate a more flexible labeling schema - can you label the edges using the 'extra' tp index?\n",
    "Can this learn more interesting structures for the graph(s)?\n",
    "# Solution: Use the same node in different graphs - same as above but implementation-wise easier to do.\n",
    "\n",
    "#TODO: What information do we use to weight the edges in the graph?\n",
    "Differences in rechit parameters?\n",
    "Rechit vs. Track Parameters?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__new__() keywords must be strings",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-c8a92bac8b5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muncut_rechit_ids_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/uncut_rechit_ids_.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bytes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/projects/tsc-cern/TrackingNtuples/TrackingNtuples/scripts/mlenv/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 440\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/tsc-cern/TrackingNtuples/TrackingNtuples/scripts/mlenv/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0mpickle_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/tsc-cern/TrackingNtuples/TrackingNtuples/scripts/mlenv/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_new_Index\u001b[0;34m(cls, d)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_new_PeriodIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_new_PeriodIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __new__() keywords must be strings"
     ]
    }
   ],
   "source": [
    "uncut_rechit_ids_ = np.load('data/uncut_rechit_ids_.npy', encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6934, 6934)\n",
      "(6789, 6789)\n",
      "(7285, 7285)\n",
      "(10748, 10748)\n",
      "(6317, 6317)\n",
      "(8703, 8703)\n",
      "(6743, 6743)\n",
      "(6068, 6068)\n",
      "(7402, 7402)\n",
      "(4349, 4349)\n",
      "(5808, 5808)\n",
      "(6627, 6627)\n",
      "(4466, 4466)\n",
      "(3775, 3775)\n",
      "(9901, 9901)\n",
      "(5895, 5895)\n",
      "(6184, 6184)\n",
      "(4778, 4778)\n",
      "(4289, 4289)\n",
      "(8102, 8102)\n",
      "(4527, 4527)\n",
      "(7226, 7226)\n",
      "(8050, 8050)\n",
      "(8302, 8302)\n",
      "(7389, 7389)\n",
      "(6620, 6620)\n",
      "(5443, 5443)\n",
      "(6659, 6659)\n",
      "(4803, 4803)\n",
      "(5065, 5065)\n",
      "(6184, 6184)\n",
      "(5016, 5016)\n",
      "(4935, 4935)\n",
      "(3111, 3111)\n",
      "(5055, 5055)\n",
      "(4759, 4759)\n",
      "(3265, 3265)\n",
      "(6186, 6186)\n",
      "(4894, 4894)\n",
      "(5664, 5664)\n",
      "(8356, 8356)\n",
      "(5298, 5298)\n",
      "(8703, 8703)\n",
      "(2289, 2289)\n",
      "(4243, 4243)\n",
      "(6282, 6282)\n",
      "(2159, 2159)\n",
      "(6652, 6652)\n",
      "(5864, 5864)\n",
      "(5762, 5762)\n",
      "(7479, 7479)\n",
      "(5114, 5114)\n",
      "(6028, 6028)\n",
      "(5423, 5423)\n",
      "(7606, 7606)\n",
      "(11047, 11047)\n",
      "(5067, 5067)\n",
      "(10932, 10932)\n",
      "(5516, 5516)\n",
      "(6105, 6105)\n",
      "(8263, 8263)\n",
      "(4217, 4217)\n",
      "(4109, 4109)\n",
      "(7420, 7420)\n",
      "(8165, 8165)\n",
      "(7787, 7787)\n",
      "(9206, 9206)\n",
      "(4555, 4555)\n",
      "(4460, 4460)\n",
      "(2776, 2776)\n",
      "(5316, 5316)\n",
      "(3337, 3337)\n",
      "(5529, 5529)\n",
      "(8078, 8078)\n",
      "(4849, 4849)\n",
      "(3497, 3497)\n",
      "(5446, 5446)\n",
      "(4517, 4517)\n",
      "(3294, 3294)\n",
      "(9230, 9230)\n",
      "(3557, 3557)\n",
      "(6807, 6807)\n",
      "(6613, 6613)\n",
      "(3815, 3815)\n",
      "(10842, 10842)\n",
      "(6951, 6951)\n",
      "(6702, 6702)\n",
      "(7006, 7006)\n",
      "(5997, 5997)\n",
      "(3338, 3338)\n",
      "(6156, 6156)\n",
      "(5251, 5251)\n",
      "(5132, 5132)\n",
      "(4051, 4051)\n",
      "(7454, 7454)\n",
      "(4611, 4611)\n",
      "(5788, 5788)\n",
      "(6968, 6968)\n",
      "(5727, 5727)\n",
      "(3289, 3289)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "'''TODO: Convert data to string instead of bytes and check overheads'''\n",
    "\n",
    "\n",
    "\n",
    "edge_src_ = []\n",
    "edge_dest_ = []\n",
    "\n",
    "x = []\n",
    "\n",
    "for event_id_ in range(number_of_events_):\n",
    "    track_event_df_ = track_global_df_[track_global_df_[b'event_id'] == event_id_]\n",
    "    number_of_rechits_in_event_ = len(rechit_global_df_[rechit_global_df_[b'event_id']==event_id_])\n",
    "    \n",
    "    for track_rechit_id_array_ in track_event_df_[b'rechit_ids']:\n",
    "        uncut_rechits_ = [i for i in track_rechit_id_array_ if i in rechit_ids_['track_matched']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 1,\n",
       " 2: 2,\n",
       " 3: 3,\n",
       " 4: 4,\n",
       " 5: 5,\n",
       " 6: 6,\n",
       " 7: 7,\n",
       " 8: 8,\n",
       " 9: 9,\n",
       " 10: 10,\n",
       " 11: 11,\n",
       " 12: 12,\n",
       " 13: 13,\n",
       " 14: 14,\n",
       " 15: 15,\n",
       " 16: 16,\n",
       " 17: 17,\n",
       " 18: 18,\n",
       " 19: 19,\n",
       " 20: 20,\n",
       " 21: 21,\n",
       " 22: 22,\n",
       " 23: 23,\n",
       " 24: 24,\n",
       " 25: 25,\n",
       " 26: 26,\n",
       " 27: 27,\n",
       " 28: 28,\n",
       " 29: 29,\n",
       " 30: 30,\n",
       " 31: 31,\n",
       " 32: 32,\n",
       " 33: 33,\n",
       " 34: 34,\n",
       " 35: 35,\n",
       " 36: 36,\n",
       " 37: 37,\n",
       " 38: 38,\n",
       " 39: 39,\n",
       " 40: 40,\n",
       " 41: 41,\n",
       " 42: 42,\n",
       " 43: 43,\n",
       " 44: 44,\n",
       " 45: 45,\n",
       " 46: 46,\n",
       " 47: 47,\n",
       " 48: 48,\n",
       " 49: 49,\n",
       " 50: 50,\n",
       " 51: 51,\n",
       " 52: 52,\n",
       " 53: 53,\n",
       " 54: 54,\n",
       " 55: 55,\n",
       " 56: 56,\n",
       " 57: 57,\n",
       " 58: 58,\n",
       " 59: 59,\n",
       " 60: 60,\n",
       " 61: 61,\n",
       " 62: 62,\n",
       " 63: 63,\n",
       " 64: 64,\n",
       " 65: 65,\n",
       " 66: 66,\n",
       " 67: 67,\n",
       " 68: 68,\n",
       " 69: 69,\n",
       " 70: 70,\n",
       " 71: 71,\n",
       " 72: 72,\n",
       " 73: 73,\n",
       " 74: 74,\n",
       " 75: 75,\n",
       " 76: 76,\n",
       " 77: 77,\n",
       " 78: 78,\n",
       " 79: 79,\n",
       " 80: 80,\n",
       " 81: 81,\n",
       " 82: 82,\n",
       " 83: 83,\n",
       " 84: 84,\n",
       " 85: 85,\n",
       " 86: 86,\n",
       " 87: 87,\n",
       " 88: 88,\n",
       " 89: 89,\n",
       " 90: 90,\n",
       " 91: 91,\n",
       " 92: 92,\n",
       " 93: 93,\n",
       " 94: 94,\n",
       " 95: 95,\n",
       " 96: 96,\n",
       " 97: 97,\n",
       " 98: 98,\n",
       " 99: 99}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3-5: Start propagating messages with \"add\" aggregation.\n",
    "        return self.propagate('add', edge_index, x=x, num_nodes=x.size(0))\n",
    "\n",
    "    def message(self, x_j, edge_index, num_nodes):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 3: Normalize node features.\n",
    "        row, col = edge_index\n",
    "        deg = degree(row, num_nodes, dtype=x_j.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "\n",
    "        # Step 5: Return new node embeddings.\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "# Sample Edge Label Definition for Rechits - Adjacency List?\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Define the 2-layer GCN'''\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, 16)\n",
    "        self.conv2 = GCNConv(16, data.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA available on cmg-gpu1080\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
