{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define number of events in data\n",
    "number_of_events_ = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the DataFrames Stored during Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Refer to Data Preprocessing Notebook to Understand the Semantics and Column Headers'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Refer to Data Preprocessing Notebook to Understand the Semantics and Column Headers'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 510 ms, sys: 42.4 ms, total: 552 ms\n",
      "Wall time: 664 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "track_global_df_ = pd.read_msgpack('data/track_global_df_.msgpack')\n",
    "track_param_global_df_ = pd.read_msgpack('data/track_param_global_df_.msgpack')\n",
    "rechit_global_df_ = pd.read_msgpack('data/rechit_global_df_.msgpack')\n",
    "rechit_param_global_df_ = pd.read_msgpack('data/rechit_param_global_df_.msgpack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intermediate_df_ = track_param_global_df_[track_param_global_df_[b'track_eta'] <= 0.9]\n",
    "intermediate_df_ = intermediate_df_[intermediate_df_[b'track_pt'] <= 10]\n",
    "intermediate_df_ = intermediate_df_[intermediate_df_[b'track_pt'] >= 1]\n",
    "track_param_global_df_ = intermediate_df_[intermediate_df_[b'track_eta'] >= -0.9]\n",
    "track_global_df_ = track_global_df_.iloc[track_param_global_df_[b'track_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40 ms, sys: 10.7 ms, total: 50.7 ms\n",
      "Wall time: 72.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "track_count_ = pd.DataFrame.to_dict(pd.read_csv('data/track_count_.csv'))\n",
    "rechit_count_ = pd.DataFrame.to_dict(pd.read_csv('data/rechit_count_.csv'))\n",
    "track_ids_ = pd.DataFrame.to_dict(pd.read_csv('data/track_ids_.csv'))\n",
    "rechit_ids_ = pd.DataFrame.to_dict(pd.read_csv('data/rechit_ids_.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Graph Tuples from Hit Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nGraphs are created on a per-event basis. We build an adjacency matrix of rechits for each individual event.\\nThe rechit connections are defined by the track that they belong to.\\nThe target label for each node is taken as the first tp_index in its rechit_tp_list\\n\\n#TODO: Incorporate a more flexible labeling schema - can you label the edges using the 'extra' tp index?\\nCan this learn more interesting structures for the graph(s)?\\n# Solution: Use the same node in different graphs - same as above but implementation-wise easier to do.\\n\\n#TODO: What information do we use to weight the edges in the graph?\\nDifferences in rechit parameters?\\nRechit vs. Track Parameters?\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "'''\n",
    "Graphs are created on a per-event basis. We build an adjacency matrix of rechits for each individual event.\n",
    "The rechit connections are defined by the track that they belong to.\n",
    "The target label for each node is taken as the first tp_index in its rechit_tp_list\n",
    "\n",
    "#TODO: Incorporate a more flexible labeling schema - can you label the edges using the 'extra' tp index?\n",
    "Can this learn more interesting structures for the graph(s)?\n",
    "# Solution: Use the same node in different graphs - same as above but implementation-wise easier to do.\n",
    "\n",
    "#TODO: What information do we use to weight the edges in the graph?\n",
    "Differences in rechit parameters?\n",
    "Rechit vs. Track Parameters?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 graphs generated from data\n",
      "CPU times: user 5.52 s, sys: 23.7 ms, total: 5.55 s\n",
      "Wall time: 5.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "'''TODO: Convert keys to string instead of bytes and check overheads'''\n",
    "\n",
    "data_dict_list_ = []\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# Global Features are track-based so they vary in length per-event\n",
    "# We find the maximum number of tracks that correspond to max_len of global feature vector\n",
    "# Is it a good idea to zero-pad global feature vectors less than max_len?\n",
    "GLOBAL_FEATURES_LEN_ = max([\n",
    "    len(\n",
    "        track_global_df_[track_global_df_[b'event_id']==event_id_]\n",
    "    ) for event_id_ in range(100)\n",
    "])\n",
    "\n",
    "for event_id_ in range(number_of_events_):\n",
    "    data_dict_ = {}\n",
    "    senders_ = []\n",
    "    receivers_ = []\n",
    "    \n",
    "    track_event_df_ = track_global_df_[track_global_df_[b'event_id'] == event_id_]\n",
    "    track_param_df_ = track_param_global_df_.loc[track_event_df_[b'track_id']]\n",
    "    track_df_ = track_event_df_.merge(track_param_df_)\n",
    "\n",
    "    # Sort the tracks according to increasing track_eta and associate a label with each track\n",
    "    track_df_.sort_values(b'track_eta', ascending=True, inplace=True)\n",
    "    track_df_.index = pd.RangeIndex(len(track_df_.index))  \n",
    "\n",
    "    rechit_event_df_ = rechit_global_df_[rechit_global_df_[b'event_id']==event_id_]\n",
    "    rechit_param_df_ = rechit_param_global_df_[rechit_param_global_df_[b'event_id']==event_id_]\n",
    "    rechit_param_df_.index = pd.RangeIndex(len(rechit_param_df_.index))  \n",
    "    if len(rechit_event_df_) != len(rechit_param_df_):\n",
    "        print(\"Error - param data and event data are not of equal length!\")\n",
    "    \n",
    "    number_of_rechits_in_event_ = len(rechit_event_df_)\n",
    "    \n",
    "    # Set the node features as the track features that they belong to\n",
    "    node_labels_ = np.array(rechit_param_df_[b'rechit_local_id'].tolist()).astype(int)\n",
    "    \n",
    "    # Originally, we were setting node-level features based on the nodes but that can be done\n",
    "    # for the test data set; instead here we can set the node-level features as the track features\n",
    "    # at least for training and \"learn\" the track-level features (eta) based on which we can cluster the nodes?\n",
    "    # The question still remains how do we initialize the edges ???\n",
    "    \n",
    "    # Update: Reverting to node-level features for each node as of now \n",
    "    # Modify it to combine some form of track-level features (target?)\n",
    "    rechit_feature_vector_ = np.transpose(np.array([rechit_param_df_[b'rechit_r'].tolist(),\n",
    "                                  rechit_param_df_[b'rechit_eta'].tolist(),\n",
    "                                  rechit_param_df_[b'rechit_phi'].tolist()]))\n",
    "    rechit_feature_vector_ = scaler.fit_transform(rechit_feature_vector_)\n",
    "    node_feature_vector_ = rechit_feature_vector_\n",
    "    \n",
    "    # Edge Features uses the track matches to define edge features for each set of nodes\n",
    "    # We are not relying on edges for now but this will be relevant for message-passing in graph neural networks\n",
    "    edge_feature_vector_ = []\n",
    "    \n",
    "    # For each track, append to the list of source nodes, destination nodes, and node feature vectors\n",
    "    # Keep track of the node label equal to len(track_df_)\n",
    "    node_label_i_ = 0\n",
    "    \n",
    "    for row in track_df_.itertuples():\n",
    "        track_edge_features_ = []\n",
    "        # The itertuples() method for dataframes requires acccess by rows\n",
    "        # The matched_rechit_ids array is present in the third column of this 'row'\n",
    "        track_rechit_id_array_ = row[2]\n",
    "        #print (track_rechit_id_array_)\n",
    "        src_vertices_ = []\n",
    "        dest_vertices_ = []\n",
    "        # Sort the rechits based on values of Rechit R\n",
    "        # Start track building from the inside and move all the way outside\n",
    "        final_rechits_ = sorted(track_rechit_id_array_, \n",
    "                                key=lambda hit_: rechit_param_df_.loc[int(hit_)][b'rechit_r'])\n",
    "        if len(final_rechits_) < 2:\n",
    "            # Increment the node label\n",
    "            node_label_i_ += 1\n",
    "            continue\n",
    "        elif len(final_rechits_) == 2:\n",
    "            src_vertices_.append(final_rechits_[0])\n",
    "            dest_vertices_.append(final_rechits_[1])\n",
    "        \n",
    "        # In order to extend this to 2 skip-connections (expanding to the assumption that 3 hits can be \n",
    "        # on the same layer, thus all of them should be connected to a hit on the next layer)\n",
    "        # Create another else case for len(final_rechits_) == 3: and add the corresponding vertices\n",
    "        # to src and dest arrays. Then you can modify the addition procedure to include src+[3:] and dest+[:-3]\n",
    "        # So you will have (1,2), (1,3), and (1,4) edges as a simple example of adding 2-skip-connections\n",
    "        else:\n",
    "            # Add the edges starting from node a and going to both a+1 and a+2\n",
    "            # We define this as 1-skip-connection because hits might lie on the same layer\n",
    "            # We originally sort them by the radius to ensure skip-connections have a meaning\n",
    "            src_vertices_.extend(final_rechits_[:-1]+final_rechits_[:-2])\n",
    "            dest_vertices_.extend(final_rechits_[1:]+final_rechits_[2:])\n",
    "        # Increment the node label\n",
    "        node_label_i_ += 1\n",
    "        senders_.extend(np.array(src_vertices_).astype(int))\n",
    "        receivers_.extend(np.array(dest_vertices_).astype(int))\n",
    "        # Define the edge feature vectors of same length as number of vertices\n",
    "        # Indices 7, 8, 9 correspond to track eta, phi, and qoverp values respectively\n",
    "        track_edge_features_ = np.array([[row[7], row[8], row[9]]] * len(src_vertices_))\n",
    "        edge_feature_vector_.append(track_edge_features_)\n",
    "    if node_label_i_ != len(track_df_):\n",
    "        print(\"Error: Node Labels don't match the number of tracks - spurious labels generated?\", node_label_i_, len(track_df_))\n",
    "    \n",
    "    # Define a zero-padded global feature vector\n",
    "    if len(track_df_) < GLOBAL_FEATURES_LEN_:\n",
    "        global_feature_vector_ = np.array(track_df_[b'track_eta'].tolist() + [0]*(GLOBAL_FEATURES_LEN_ - len(track_df_)))\n",
    "    else: \n",
    "        global_feature_vector_ = np.array(track_df_[b'track_eta'].values)\n",
    "    \n",
    "    if len(track_edge_features_) != len(dest_vertices_):\n",
    "        print(len(track_edge_features_), len(dest_vertices_))\n",
    "        print(\"Edge features and number of destination edges do not match in event\", event_id_)\n",
    "    \n",
    "    data_dict_ = {\n",
    "    \"nodes\": node_feature_vector_,\n",
    "    \"edges\": edge_feature_vector_,\n",
    "    \"senders\": senders_,\n",
    "    \"receivers\": receivers_\n",
    "    }\n",
    "    data_dict_list_.append(data_dict_)\n",
    "print(len(data_dict_list_), \"graphs generated from data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['match_count', 'rechit_local_ids', 'event_id', 'track_tp_index', 'track_id', 'rechit_ids']\n"
     ]
    }
   ],
   "source": [
    "# TODO: Set new string names of column to avoid using b'' syntax to access the rows and columns\n",
    "new_names = []\n",
    "for column_name in track_global_df_.columns:\n",
    "    new_names.append(str(column_name.decode()))\n",
    "print (new_names)    \n",
    "#track_global_df_.columns = new_names\n",
    "#track_global_df_.event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from graph_nets import blocks\n",
    "from graph_nets import graphs\n",
    "from graph_nets import modules\n",
    "from graph_nets import utils_np\n",
    "from graph_nets import utils_tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import sonnet as snt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Failed to convert object of type <class 'list'> to Tensor. Contents: [array([[0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807]]), array([[0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093]]), array([[ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234]]), array([[ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934]]), array([[0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235]])]. Consider casting elements to a supported type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/projects/tsc-cern/TrackingNtuples/TrackingNtuples/scripts/mlenv/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/tsc-cern/TrackingNtuples/TrackingNtuples/scripts/mlenv/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/tsc-cern/TrackingNtuples/TrackingNtuples/scripts/mlenv/lib/python3.6/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     60\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 61\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got array([[0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807]])",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-86e46617acb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtracking_graphs_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dicts_to_graphs_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict_list_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/projects/tsc-cern/TrackingNtuples/TrackingNtuples/scripts/mlenv/lib/python3.6/site-packages/graph_nets/utils_tf.py\u001b[0m in \u001b[0;36mdata_dicts_to_graphs_tuple\u001b[0;34m(data_dicts, name)\u001b[0m\n\u001b[1;32m    950\u001b[0m   \u001b[0mutils_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_valid_sets_of_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dicts\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m     \u001b[0mdata_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_compatible_data_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphsTuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_concatenate_data_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/tsc-cern/TrackingNtuples/TrackingNtuples/scripts/mlenv/lib/python3.6/site-packages/graph_nets/utils_tf.py\u001b[0m in \u001b[0;36m_to_compatible_data_dicts\u001b[0;34m(data_dicts)\u001b[0m\n\u001b[1;32m    586\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mSENDERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRECEIVERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_NODE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_EDGE\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/tsc-cern/TrackingNtuples/TrackingNtuples/scripts/mlenv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m   1048\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/tsc-cern/TrackingNtuples/TrackingNtuples/scripts/mlenv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/tsc-cern/TrackingNtuples/TrackingNtuples/scripts/mlenv/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                          as_ref=False):\n\u001b[1;32m    228\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/tsc-cern/TrackingNtuples/TrackingNtuples/scripts/mlenv/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/Documents/projects/tsc-cern/TrackingNtuples/TrackingNtuples/scripts/mlenv/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    529\u001b[0m       raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\u001b[1;32m    530\u001b[0m                       \u001b[0;34m\"Contents: %s. Consider casting elements to a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                       \"supported type.\" % (type(values), values))\n\u001b[0m\u001b[1;32m    532\u001b[0m     \u001b[0mtensor_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Failed to convert object of type <class 'list'> to Tensor. Contents: [array([[0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807],\n       [0.01188118, 1.62244558, 0.15238807]]), array([[0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093],\n       [0.05509782, 1.52089953, 0.12771093]]), array([[ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234],\n       [ 0.06538846,  1.44177617, -0.20591234]]), array([[ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934],\n       [ 0.23156771, -2.14679573, -0.73222934]]), array([[0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235],\n       [0.34483095, 1.05768893, 0.62273235]])]. Consider casting elements to a supported type."
     ]
    }
   ],
   "source": [
    "tracking_graphs_tuple = utils_tf.data_dicts_to_graphs_tuple(data_dict_list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i for i in tracking_graphs_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "seed = 2\n",
    "rand = np.random.RandomState(seed=seed)\n",
    "\n",
    "# Model parameters.\n",
    "# Number of processing (message-passing) steps.\n",
    "num_processing_steps_tr = 10\n",
    "num_processing_steps_ge = 10\n",
    "\n",
    "# Training loss.\n",
    "loss_ops_tr = create_loss_ops(target_ph, output_ops_tr)\n",
    "\n",
    "# Loss across processing steps.\n",
    "loss_op_tr = sum(loss_ops_tr) / num_processing_steps_tr\n",
    "\n",
    "# Test/generalization loss.\n",
    "loss_ops_ge = create_loss_ops(target_ph, output_ops_ge)\n",
    "loss_op_ge = loss_ops_ge[-1]  # Loss from final processing step.\n",
    "\n",
    "# Optimizer.\n",
    "learning_rate = 1e-3\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "step_op = optimizer.minimize(loss_op_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell resets the Tensorflow session, but keeps the same computational\n",
    "# graph.\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "last_iteration = 0\n",
    "logged_iterations = []\n",
    "losses_tr = []\n",
    "corrects_tr = []\n",
    "solveds_tr = []\n",
    "losses_ge = []\n",
    "corrects_ge = []\n",
    "solveds_ge = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_every_seconds = 20\n",
    "\n",
    "print(\"# (iteration number), T (elapsed seconds), \"\n",
    "      \"Ltr (training loss), Lge (test/generalization loss), \"\n",
    "      \"Ctr (training fraction nodes/edges labeled correctly), \"\n",
    "      \"Str (training fraction examples solved correctly), \"\n",
    "      \"Cge (test/generalization fraction nodes/edges labeled correctly), \"\n",
    "      \"Sge (test/generalization fraction examples solved correctly)\")\n",
    "\n",
    "start_time = time.time()\n",
    "last_log_time = start_time\n",
    "for iteration in range(last_iteration, num_training_iterations):\n",
    "  last_iteration = iteration\n",
    "  feed_dict, _ = create_feed_dict(rand, batch_size_tr, num_nodes_min_max_tr,\n",
    "                                  theta, input_ph, target_ph)\n",
    "  train_values = sess.run({\n",
    "      \"step\": step_op,\n",
    "      \"target\": target_ph,\n",
    "      \"loss\": loss_op_tr,\n",
    "      \"outputs\": output_ops_tr\n",
    "  },\n",
    "                          feed_dict=feed_dict)\n",
    "  the_time = time.time()\n",
    "  elapsed_since_last_log = the_time - last_log_time\n",
    "  if elapsed_since_last_log > log_every_seconds:\n",
    "    last_log_time = the_time\n",
    "    feed_dict, raw_graphs = create_feed_dict(\n",
    "        rand, batch_size_ge, num_nodes_min_max_ge, theta, input_ph, target_ph)\n",
    "    test_values = sess.run({\n",
    "        \"target\": target_ph,\n",
    "        \"loss\": loss_op_ge,\n",
    "        \"outputs\": output_ops_ge\n",
    "    },\n",
    "                           feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5dc0a7d8b5cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMessagePassing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_self_loops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMessagePassing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3-5: Start propagating messages with \"add\" aggregation.\n",
    "        return self.propagate('add', edge_index, x=x, num_nodes=x.size(0))\n",
    "\n",
    "    def message(self, x_j, edge_index, num_nodes):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 3: Normalize node features.\n",
    "        row, col = edge_index\n",
    "        deg = degree(row, num_nodes, dtype=x_j.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "\n",
    "        # Step 5: Return new node embeddings.\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "# Sample Edge Label Definition for Rechits - Adjacency List?\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Define the 2-layer GCN'''\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, 16)\n",
    "        self.conv2 = GCNConv(16, data.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CUDA available on cmg-gpu1080\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
